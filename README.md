# users_sessions
Предположим данные о событиях пользователей(сессиях) поступают каждый день в виде json( например, из Kafka). Нам необходимо ежедневно загружать этот json в ClickHouse и там его обрабатывать для удобного хранения всей истории пользовательских сессий.

1. Запустить docker-compose.yaml командой `docker-compose up -d`
2. После нескольких минут в браузере необходимо перейти по адресу:  
http://localhost:8080/admin/  

3. ETL процесс состоит из 2 тасок
3.1. Данные в сыром виде поступают в таблицу с движком TinyLog (в официальной документации к clickhouse написано, что такой движок можно использовать для хранения промежуточных данных)
3.2. Данные пригодные для аналитики помещаются уже в таблицу с движклм MergeTree (используется потому что мы можем сразу данные партицировать, накладывать индексы, делать сортировку) в общем приводить данные к боевому анализу))
